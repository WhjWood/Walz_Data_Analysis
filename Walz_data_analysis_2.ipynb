{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the path to the experiment folder eg r\"F:\\Light_curves\\Experiment1\"\n",
    "# There should be a report (csv) and a folder called FastKinetics (no space with capitals) in this folder.\n",
    "path = r\"/media/will/3930-2B1A/Light_curve_05_08_19/Experiment1\"\n",
    "\n",
    "# What name would you like to give to the results file? \n",
    "name = \"Experiment1\"\n",
    "\n",
    "# Enter the pulse width (ms)\n",
    "pulse_width = 300\n",
    "\n",
    "# Do you have a report file in the path folder you wish to add the kinetics to? True or False (notice the capitals)\n",
    "integrate_report = True\n",
    "\n",
    "# what is the width of the initial slope? (ms)\n",
    "fitting_window = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats, signal\n",
    "\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "def scale_fast_kinetics(df,pulse_width,columns):\n",
    "\n",
    "    for col in columns:\n",
    "        series = df[col]\n",
    "        top = np.mean(series[(df[\"time/ms\"]>=pulse_width-5) & (df[\"time/ms\"]<=pulse_width)])\n",
    "        bottom = np.mean(series[-100:])\n",
    "        df[col] = (series-bottom)/(top-bottom)\n",
    "    return df\n",
    "    \n",
    "\n",
    "def Kinetics_Fitting(path, pulse_width = 300, integrate_report = False, Report_DF = None,fitting_window =10, plot_results=False):       \n",
    "    if not os.path.exists(path+\"/FastKinetics\"):\n",
    "        print(\"The folder\",str(path+\"/FastKinetics\"),\"does not exist\")\n",
    "        return Report_DF\n",
    "    # test the number of fast kinetic files = number of SP\n",
    "    if integrate_report == True:\n",
    "        if len(Report_DF[Report_DF[\"ID\"]==\"SP\"]) != len(os.listdir(path+\"/FastKinetics\")):\n",
    "            print(\"Integration with report not possible. The number of files in FastKinetics is not equal to the number of SPs\")\n",
    "            return(Report_DF)\n",
    "    \n",
    "    FK_columns = [\"Fluo k\",\"Fluo r value\", \"Fluo p value\", \"Fluo std err\",\"Fluo lag\",\n",
    "                  \"P700 k\",\"P700 r value\", \"P700 p value\", \"P700 std err\", \"P700 lag\",\n",
    "                  \"PC k\",\"PC r value\", \"PC p value\", \"PC std err\",\"PC lag\",\n",
    "                  \"Fd k\",\"Fd r value\", \"Fd p value\", \"Fd std err\",\"Fd lag\",\n",
    "                  \"P700 fit t1/2\",\"PC fit t1/2\",\"Fd fit t1/2\",\"Fluo observed t1/2\",\n",
    "                  \"P700 observed t1/2\",\"PC observed t1/2\",\"Fd observed t1/2\"]\n",
    "    # \"Fluo k\",\"Fluo r value\", \"Fluo p value\", \"Fluo std err\",\n",
    "    FK_data = []\n",
    "    for fk in os.listdir(path+\"/FastKinetics\"):\n",
    "        fastkin_df = pd.read_csv(path+\"/FastKinetics\"+\"/\"+fk,sep=';',skiprows=1)\n",
    "        fastkin_df[\"Fluo deltaI/I x10e3\"] = signal.savgol_filter(fastkin_df[\"Fluo deltaI/I x10e3\"],21,1)\n",
    "        fastkin_df[\"Fd rel.\"] = signal.savgol_filter(fastkin_df[\"Fd rel.\"],31,1)\n",
    "\n",
    "        cols_to_normalise = [\"Fluo deltaI/I x10e3\",\"PC rel.\",\"P700 rel.\",\"Fd rel.\"]\n",
    "        #x = fastkin_df[cols_to_normalise[:]].values #returns a numpy array\n",
    "        #min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        #x_scaled = min_max_scaler.fit_transform(x)\n",
    "        normalised_df = scale_fast_kinetics(fastkin_df,pulse_width,cols_to_normalise)#pd.DataFrame(x_scaled,columns = cols_to_normalise)\n",
    "        \n",
    "        #normalised_df.to_csv(path+\"/\"+name+\"_\"+\"Normalised_kinetics_\"+fk+\".CSV\")\n",
    "        #normalised_df[\"Fluo deltaI/I x10e3\"] = normalised_df[\"Fluo deltaI/I x10e3\"].rolling(window=3).mean()\n",
    "        #normalised_df[\"Fd rel.\"] = normalised_df[\"Fd rel.\"] .rolling(window=3).mean()\n",
    "        \n",
    "        \n",
    "        # DIRK initial rate (linear fit)\n",
    "        lag =  3# there is a 2 ms lag\n",
    "        DIRK_df_P700 = normalised_df[(fastkin_df[\"time/ms\"]>=pulse_width+lag) & (fastkin_df[\"time/ms\"]<=pulse_width+fitting_window)]\n",
    "        DIRK_df = normalised_df[(fastkin_df[\"time/ms\"]>=pulse_width+lag) & (fastkin_df[\"time/ms\"]<=pulse_width+10)]\n",
    "        #DIRK_df[\"time/ms\"]= pd.Series([x/2.0 for x in range(len(DIRK_df.index))], index = DIRK_df.index)\n",
    "\n",
    "        # Generated linear fit\n",
    "        P700_slope, P700_intercept, P700_r_value, P700_p_value, P700_std_err = stats.linregress(np.array(DIRK_df_P700[\"time/ms\"]),np.array(DIRK_df_P700[\"P700 rel.\"]))\n",
    "        P700_lag = ((1-P700_intercept)/P700_slope) - pulse_width\n",
    "        \n",
    "        PC_slope, PC_intercept, PC_r_value, PC_p_value, PC_std_err = stats.linregress(np.array(DIRK_df[\"time/ms\"]),np.array(DIRK_df[\"PC rel.\"]))\n",
    "        PC_lag = ((1-PC_intercept)/PC_slope) - pulse_width\n",
    "        \n",
    "        Fd_slope, Fd_intercept, Fd_r_value, Fd_p_value, Fd_std_err = stats.linregress(np.array(DIRK_df[\"time/ms\"]),np.array(DIRK_df[\"Fd rel.\"]))\n",
    "        Fd_lag = ((1-Fd_intercept)/Fd_slope) - pulse_width\n",
    "        \n",
    "        Fluo_slope, Fluo_intercept, Fluo_r_value, Fluo_p_value, Fluo_std_err = stats.linregress(np.array(DIRK_df[\"time/ms\"]),np.array(DIRK_df[\"Fluo deltaI/I x10e3\"]))\n",
    "        Fluo_lag = ((1-Fluo_intercept)/Fluo_slope) - pulse_width\n",
    "        \n",
    "        # Half time determination \n",
    "        DIRK_HALFTIME_df = normalised_df[(fastkin_df[\"time/ms\"]>=pulse_width) & (fastkin_df[\"time/ms\"]<=pulse_width+100)]\n",
    "        DIRK_HALFTIME_df[\"time/ms\"]= pd.Series([x/2.0 for x in range(len(DIRK_HALFTIME_df.index))], index = DIRK_HALFTIME_df.index)\n",
    "\n",
    "        # second normalisation and baseline correction\n",
    "        \"\"\"\n",
    "        DIRK_HALFTIME_df[\"Fluo deltaI/I x10e3\"] -= np.mean(np.array(DIRK_HALFTIME_df[\"Fluo deltaI/I x10e3\"])[-100:])\n",
    "        DIRK_HALFTIME_df[\"Fluo deltaI/I x10e3\"] /= np.mean(np.array(DIRK_HALFTIME_df[\"Fluo deltaI/I x10e3\"])[:3])\n",
    "\n",
    "        DIRK_HALFTIME_df[\"PC rel.\"] -= np.mean(np.array(DIRK_HALFTIME_df[\"PC rel.\"])[-100:])\n",
    "        DIRK_HALFTIME_df[\"PC rel.\"] /= np.mean(np.array(DIRK_HALFTIME_df[\"PC rel.\"])[:3])\n",
    "\n",
    "        DIRK_HALFTIME_df[\"P700 rel.\"] -= np.mean(np.array(DIRK_HALFTIME_df[\"P700 rel.\"])[-100:])\n",
    "        DIRK_HALFTIME_df[\"P700 rel.\"] /= np.mean(np.array(DIRK_HALFTIME_df[\"P700 rel.\"])[:3])\n",
    "\n",
    "        DIRK_HALFTIME_df[\"Fd rel.\"] = 1 - DIRK_HALFTIME_df[\"Fd rel.\"]\n",
    "        DIRK_HALFTIME_df[\"Fd rel.\"] -= np.mean(np.array(DIRK_HALFTIME_df[\"Fd rel.\"])[-100:])\n",
    "        DIRK_HALFTIME_df[\"Fd rel.\"] /= np.mean(np.array(DIRK_HALFTIME_df[\"Fd rel.\"])[:3])\n",
    "\n",
    "        #DIRK_HALFTIME_df[\"Fd rel.\"] = DIRK_HALFTIME_df[\"Fd rel.\"].rolling(window=4).mean() # to smooth out the noisy Fd signal\n",
    "        #DIRK_HALFTIME_df[\"Fluo deltaI/I x10e3\"] = DIRK_HALFTIME_df[\"Fluo deltaI/I x10e3\"].rolling(window=4).mean() \n",
    "        \n",
    "        \"\"\"\n",
    "        # Find Half-time (+/- 10 %)\n",
    "        Fluo_HT_obs = np.mean(np.array(DIRK_HALFTIME_df[(DIRK_HALFTIME_df[\"Fluo deltaI/I x10e3\"]<=0.55) & (DIRK_HALFTIME_df[\"Fluo deltaI/I x10e3\"]>=0.45)][\"time/ms\"]))\n",
    "        P700_HT_obs = np.mean(np.array(DIRK_HALFTIME_df[(DIRK_HALFTIME_df[\"P700 rel.\"]<=0.55) & (DIRK_HALFTIME_df[\"P700 rel.\"]>=0.45)][\"time/ms\"]))\n",
    "        PC_HT_obs = np.mean(np.array(DIRK_HALFTIME_df[(DIRK_HALFTIME_df[\"PC rel.\"]<=0.55) & (DIRK_HALFTIME_df[\"PC rel.\"]>=0.45)][\"time/ms\"]))\n",
    "        Fd_HT_obs = np.mean(np.array(DIRK_HALFTIME_df[(DIRK_HALFTIME_df[\"Fd rel.\"]<=0.55) & (DIRK_HALFTIME_df[\"Fd rel.\"]>=0.45)][\"time/ms\"]))\n",
    "        \n",
    "        P700_HT = np.log(2)/np.abs(P700_slope)\n",
    "        PC_HT = np.log(2)/np.abs(PC_slope)\n",
    "        Fd_HT = np.log(2)/np.abs(Fd_slope)\n",
    "        FK_data.append([Fluo_slope, Fluo_r_value, Fluo_p_value, Fluo_std_err,Fluo_lag,\n",
    "                        P700_slope,P700_r_value, P700_p_value, P700_std_err,P700_lag,\n",
    "                        PC_slope,PC_r_value, PC_p_value, PC_std_err,PC_lag,\n",
    "                        Fd_slope,Fd_r_value, Fd_p_value, Fd_std_err, Fd_lag,\n",
    "                        P700_HT, PC_HT, Fd_HT,Fluo_HT_obs, P700_HT_obs, PC_HT_obs, Fd_HT_obs])\n",
    "        \n",
    "        if plot_results == True:\n",
    "                # plot DIRK\n",
    "                cols = [\"PC rel.\",\"P700 rel.\",\"Fd rel.\"]\n",
    "                if not os.path.exists(path+\"/DIRK_Halftime\"):\n",
    "                    os.makedirs(path+\"/DIRK_Halftime\")\n",
    "\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                for column in cols:\n",
    "                    fig=plt.figure()\n",
    "                    ax=fig.add_subplot(111)\n",
    "                    ax.set_xlabel(\"Time (ms)\")\n",
    "                    plt.scatter(np.array(DIRK_df[\"time/ms\"]),np.array(DIRK_df[column]),s=0.1,color='k')\n",
    "\n",
    "                    plt.savefig(path+\"/DIRK_Halftime/\"+column+fk[:-4]+\".png\",format='png',dpi=600)\n",
    "                    plt.clf()\n",
    "                    plt.cla()\n",
    "                    plt.close('all')\n",
    "\n",
    "\n",
    "    if integrate_report == True: \n",
    "        DIRK_results_df = pd.DataFrame(columns = FK_columns, data = np.array(FK_data), index = Report_DF.index )\n",
    "        results_df = pd.merge(Report_DF,DIRK_results_df,on = Report_DF.index)\n",
    "        results_df = results_df[['Date', 'Time', 'Rec.Time', 'Action', 'ID', 'Name', 'Temp',\n",
    "               'PAR', 'F(I)', \"Fo,Fo'\", \"Fm,Fm'\", 'FMTm', 'F', 'Y(II)', 'Y(4S)',\n",
    "               'ETR(II)', 'Y(NO)', 'Y(NPQ)', 'NPQ', 'qN', 'qP', 'qL', 'F/Fm', \"Fm'/Fm\",\n",
    "               'P700ox', \"P700m,P700m'\", 'Y(I)', 'Y(ND)', 'Y(NA)', 'ETR(I)', 'PCox',\n",
    "               \"PCm,PCm'\", 'Rel PCox', \"Rel PCm'\", 'Fdred', \"Fdm,Fdm'\", 'Rel Fdred',\n",
    "               \"Rel Fdm'\",\"Fluo k\",\"Fluo r value\", \"Fluo p value\", \"Fluo std err\",\"Fluo lag\",\n",
    "                  \"P700 k\",\"P700 r value\", \"P700 p value\", \"P700 std err\", \"P700 lag\",\n",
    "                  \"PC k\",\"PC r value\", \"PC p value\", \"PC std err\",\"PC lag\",\n",
    "                  \"Fd k\",\"Fd r value\", \"Fd p value\", \"Fd std err\",\"Fd lag\",\n",
    "                  \"P700 fit t1/2\",\"PC fit t1/2\",\"Fd fit t1/2\",\n",
    "                  \"Fluo observed t1/2\",\"P700 observed t1/2\",\"PC observed t1/2\",\"Fd observed t1/2\"]]\n",
    "    else:\n",
    "        results_df = pd.DataFrame(columns = FK_columns, data = np.array(FK_data))\n",
    "    return results_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# load report\n",
    "for f in dir_list:\n",
    "    if (f.endswith(\".CSV\") or f.endswith(\".csv\")) and not (f.endswith(\"Results.CSV\") or f.endswith(\"Results.csv\")):\n",
    "        file_path = path+\"/\"+str(f)\n",
    "        Report_DF = pd.read_csv(file_path,sep=';',skiprows=1)\n",
    "        Report_DF = Report_DF[Report_DF[\"ID\"]==\"SP\"]\n",
    "\n",
    "        \n",
    "results_df = Kinetics_Fitting(path, pulse_width = pulse_width, integrate_report = integrate_report, Report_DF = Report_DF,fitting_window =fitting_window,plot_results=True)\n",
    "\n",
    "\n",
    "# Make a time column in seconds/minutes from start\n",
    "time_in_seconds = []\n",
    "time_in_minutes = []\n",
    "for i in results_df[\"Time\"]:\n",
    "    t = i.split(\":\")\n",
    "    s = int(t[1])*60 + int(t[2])\n",
    "    m = float(t[1]) + float(t[2])/60.0\n",
    "    time_in_seconds.append(s)\n",
    "    time_in_minutes.append(m)\n",
    "results_df[\"Time/s\"] = pd.Series(time_in_seconds,index=results_df.index)\n",
    "results_df[\"Time/min\"] = pd.Series(time_in_minutes,index=results_df.index)\n",
    "\n",
    "# other engineered features (1-qL, YI/YII, ETR(I)-ETR(II))\n",
    "results_df[\"1-qL\"] = 1 - results_df[\"qL\"]\n",
    "results_df[\"Y(I)/Y(II)\"] = results_df[\"Y(I)\"] / results_df[\"Y(II)\"]\n",
    "results_df[\"ETR(I)-ETR(II)\"] = results_df[\"ETR(I)\"] - results_df[\"ETR(II)\"]\n",
    "\n",
    "results_df.to_csv(path+\"/\"+name+\"_\"+\"Results.CSV\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
